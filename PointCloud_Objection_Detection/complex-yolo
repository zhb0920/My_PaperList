摘要。基于激光雷达的三维物体检测对于自动驾驶是不可避免的，因为它直接与环境理解相关联，因此为预测和运动规划奠定了基础。实时推断高度稀疏的3D数据的能力对于除自动车辆之外的许多其他应用领域是一个不适定的问题，例如，增强现实，个人机器人或工业自动化。我们介绍了Complex-YOLO，这是一种仅在点云上的最先进的实时3D物体检测网络。在这项工作中，我们描述了一个网络，通过特定的复杂回归策略扩展YOLOv2，一个快速的2D标准物体探测器，用于估算笛卡尔空间中的多级3D盒子。因此，我们提出了一个特定的欧拉区域提议网络（E-RPN），通过向回归网络添加虚数和实数分数来估计对象的姿态。这最终在一个封闭的复杂空间中，避免了单角度估计所产生的奇点。 E-RPN支持在训练期间很好地概括。我们在KITTI基准测试套件上的实验表明，我们在效率方面优于当前领先的3D物体检测方法。我们通过比最快的竞争对手快五倍以上的速度，为汽车，行人和骑行者提供最先进的结果。此外，我们的模型能够同时高精度地估计所有八个KITTI级别，包括货车，卡车或坐着的行人。
由于近年来汽车激光雷达传感器的强劲改进，点云处理对于自动驾驶变得越来越重要。 供应商的传感器能够实时提供周围环境的3D点。 优点是直接测量包围物体的距离[1]。 这允许我们开发用于自动驾驶的物体检测算法，其在3D中准确地估计不同物体的位置和航向[2] [3] [4] [5] [6] [7] [8] [9]。 与图像相比，激光雷达点云稀疏，密度变化分布在整个测量区域。 这些点是无序的，它们在本地相互作用，主要不能被分离。 点云处理应始终对基本变换不变[10] [11]。
一般而言，基于深度学习的物体检测和分类是一项众所周知的任务，并且已广泛用于图像上的二维边界框回归[12] [13] [14] [15] [16] [17] [18] [19] [20] [21]。 研究重点主要是准确性和效率之间的权衡。 在自动驾驶方面，效率更为重要。 因此，最好的物体探测器正在使用区域建议网络（RPN）[3] [22] [15]或类似的基于网格的RPN方法[13]。 这些网络非常高效，准确，甚至能够在专用硬件或嵌入式设备上运行。 点云上的对象检测仍然很少，但越来越重要。 这些应用程序需要能够预测3D边界框。 目前，主要存在三种使用深度学习的方法[3]：
1.使用多层感知器进行直接点云处理[5] [10] [11] [23]
2.利用卷积神经网络（CNN）将点云翻译成体素或图像堆栈[2] [3] [4] [6] [8] [9] [25] [26]
3.联合融合方法[2] [7]

1.这项工作通过使用新的E-RPN为3D盒估计进行可靠的角度回归来介绍Complex-YOLO。
2.我们以KITTI基准测试套件评估的高精度实时性能，比目前的领先型号快五倍以上。
3.我们估计E-RPN支持的每个3D盒子的精确方向，可以预测周围物体的轨迹。
4.与其他基于激光雷达的方法（例如[3]）相比，我们的模型在一个前向路径中有效地同时估计所有类别。

由Velodyne HDL64激光扫描仪[1]采集的单帧3D点云被转换为单个鸟瞰RGB图，覆盖面积为80m x 40m（见图4）直接在前面 传感器的起源。 灵感来自陈等人。 （MV3D）[5]，RGB图由高度，强度和密度编码。网格图的大小定义为n = 1024和m = 512.因此，我们将3D点云投影并离散为2D 网格的分辨率约为g = 8cm。 与MV3D相比，我们略微降低了单元尺寸以实现更少的量化误差，同时具有更高的输入分辨率。由于效率和性能原因，我们仅使用一个而不是多个高度图。 因此，针对覆盖区域Ω内的整个点云P∈R3计算所有三个特征通道（z r，z g，z b，其中z r，g，b∈Rm×n）。 我们考虑在PΩ的原点内的Velodyne并定义：